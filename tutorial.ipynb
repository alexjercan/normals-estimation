{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbiChRSqK5lWKAdn/KyisD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "814a9c64be33471692163c615ef658cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a527b9150b094b72b4f7dc0e88565667",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_458fbd18721f49bdbd2bb3b77fec5515",
              "IPY_MODEL_96686ed8ec2842138038dd706afc09d4"
            ]
          }
        },
        "a527b9150b094b72b4f7dc0e88565667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "458fbd18721f49bdbd2bb3b77fec5515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb892237eb5d47bfae5d3b8a89ca5a97",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 116262275,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 116262275,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff86340d173b436aba9c7f6531062097"
          }
        },
        "96686ed8ec2842138038dd706afc09d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c6757d5810949eaa5d01f51d31361fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 111M/111M [02:42&lt;00:00, 714kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f0062f35439401994500be08860d1cc"
          }
        },
        "eb892237eb5d47bfae5d3b8a89ca5a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff86340d173b436aba9c7f6531062097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c6757d5810949eaa5d01f51d31361fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f0062f35439401994500be08860d1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexjercan/normals-estimation/blob/master/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "4QysbBtih3n-",
        "outputId": "333eed82-3c90-4ef8-8f4b-8e8536a4d0f1"
      },
      "source": [
        "!pip install matplotlib==3.3.3 albumentations==0.5.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib==3.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/f2/10c822cb0ca5ebec58bd1892187bc3e3db64a867ac26531c6204663fc218/matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 239kB/s \n",
            "\u001b[?25hCollecting albumentations==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/58/63fb1d742dc42d9ba2800ea741de1f2bc6bb05548d8724aa84794042eaf2/albumentations-0.5.2-py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3) (2.8.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3) (1.19.5)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (0.16.2)\n",
            "Collecting imgaug>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (1.4.1)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/6d/92f377bece9b0ec9c893081dbe073a65b38d7ac12ef572b8f70554d08760/opencv_python_headless-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (37.6MB)\n",
            "\u001b[K     |████████████████████████████████| 37.6MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.3.3) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (1.1.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.7.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==0.5.2) (4.4.2)\n",
            "Installing collected packages: matplotlib, imgaug, opencv-python-headless, albumentations\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.5.2 imgaug-0.4.0 matplotlib-3.3.3 opencv-python-headless-4.5.1.48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7DkyXjFh5kd",
        "outputId": "8b637338-5b32-4e1c-fbe5-aa7424d55ba8"
      },
      "source": [
        "!git clone https://github.com/alexjercan/normals-estimation.git\n",
        "%cd normals-estimation\n",
        "\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup complete. Using torch 1.8.1+cu101 CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "814a9c64be33471692163c615ef658cf",
            "a527b9150b094b72b4f7dc0e88565667",
            "458fbd18721f49bdbd2bb3b77fec5515",
            "96686ed8ec2842138038dd706afc09d4",
            "eb892237eb5d47bfae5d3b8a89ca5a97",
            "ff86340d173b436aba9c7f6531062097",
            "0c6757d5810949eaa5d01f51d31361fe",
            "7f0062f35439401994500be08860d1cc"
          ]
        },
        "id": "ICcCN_OLiB4E",
        "outputId": "2e9e1236-d77d-4551-f072-82a20140a9a4"
      },
      "source": [
        "# Download bdataset\n",
        "torch.hub.download_url_to_file('https://github.com/alexjercan/depth-estimation/releases/download/v1.0/bdataset_stereo.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../ && rm tmp.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "814a9c64be33471692163c615ef658cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=116262275.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9IOxyIUiF66",
        "outputId": "95faca73-5d78-4f7d-a5ef-9165e811197d"
      },
      "source": [
        "!git pull\n",
        "!python dataset.py\n",
        "!python model.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n",
            "dataset ok\n",
            "model ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iPrJljdiIZr"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.optim\n",
        "import albumentations as A\n",
        "import my_albumentations as M\n",
        "\n",
        "from datetime import datetime as dt\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from config import DEVICE\n",
        "from model import Model, LossFunction\n",
        "from general import init_weights, load_checkpoint, save_checkpoint\n",
        "from dataset import create_dataloader\n",
        "from metrics import MetricFunction, print_single_error\n",
        "from detect import generatePredictions\n",
        "from train import train_one_epoch\n",
        "from test import run_test\n",
        "from util import save_predictions, plot_predictions\n",
        "from dataset import LoadImages\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "DATASET_ROOT = \"../bdataset_stereo\"\n",
        "TRAIN_JSON_PATH = \"train.json\"\n",
        "TEST_JSON_PATH = \"test.json\"\n",
        "IMAGES = [{\"imageL\": \"data/left.png\", \"imageR\": \"data/right.png\", \"output\": \"data/output.exr\"}]\n",
        "BATCH_SIZE = 8\n",
        "WORKERS = 8\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "EPS = 0.00000001\n",
        "MOMENTUM = 0.9\n",
        "DAMPENING = 0.1\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "BETAS = [.9, .999]\n",
        "MILESTONES = [100,150]\n",
        "GAMMA = .5\n",
        "\n",
        "NUM_EPOCHS = 200\n",
        "OUT_PATH = \"./runs\"\n",
        "LOAD_TRAIN_MODEL = False\n",
        "LOAD_TEST_MODEL = False\n",
        "CHECKPOINT_TRAIN_FILE = \"normal.pth\"\n",
        "CHECKPOINT_TEST_FILE = \"normal.pth\"\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmfqcnLnidxt"
      },
      "source": [
        "train_transform = A.Compose(\n",
        "    [\n",
        "        M.MyRandomResizedCrop(width=IMAGE_SIZE, height=IMAGE_SIZE),\n",
        "        M.MyHorizontalFlip(p=0.5),\n",
        "        M.MyVerticalFlip(p=0.1),\n",
        "        A.OneOf([\n",
        "            A.MotionBlur(p=0.2),\n",
        "            A.MedianBlur(blur_limit=3, p=0.1),\n",
        "            A.Blur(blur_limit=3, p=0.1),\n",
        "        ], p=0.2),\n",
        "        A.OneOf([\n",
        "            M.MyOpticalDistortion(p=0.3),\n",
        "            M.MyGridDistortion(p=0.1),\n",
        "            M.MyIAAPiecewiseAffine(p=0.3),\n",
        "        ], p=0.2),\n",
        "        A.OneOf([\n",
        "            A.IAASharpen(),\n",
        "            A.IAAEmboss(),\n",
        "            A.RandomBrightnessContrast(),            \n",
        "        ], p=0.3),\n",
        "        M.MyToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\n",
        "        'right_img': 'image',\n",
        "        'left_depth': 'depth',\n",
        "        'right_depth': 'depth',\n",
        "        'left_normal': 'normal',\n",
        "        'right_normal': 'normal',\n",
        "    }\n",
        ")\n",
        "\n",
        "test_transform = A.Compose(\n",
        "    [\n",
        "        M.MyToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\n",
        "        'right_img': 'image',\n",
        "        'left_depth': 'depth',\n",
        "        'right_depth': 'depth',\n",
        "        'left_normal': 'normal',\n",
        "        'right_normal': 'normal',\n",
        "    }\n",
        ")\n",
        "\n",
        "detect_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\n",
        "        'right_img': 'image',\n",
        "    }\n",
        ")\n",
        "\n",
        "_, train_dataloader = create_dataloader(DATASET_ROOT, TRAIN_JSON_PATH, \n",
        "                                        batch_size=BATCH_SIZE, transform=train_transform, \n",
        "                                        workers=WORKERS, pin_memory=True, shuffle=True)\n",
        "\n",
        "_, test_dataloader = create_dataloader(DATASET_ROOT, TEST_JSON_PATH,\n",
        "                                       batch_size=BATCH_SIZE, transform=test_transform,\n",
        "                                       workers=WORKERS, pin_memory=True, shuffle=False)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz2cvcANizZ1"
      },
      "source": [
        "model = Model()\n",
        "model.apply(init_weights)\n",
        "solver = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
        "                          lr=LEARNING_RATE, betas=BETAS, \n",
        "                          eps=EPS, weight_decay=WEIGHT_DECAY)\n",
        "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(solver, milestones=MILESTONES, gamma=GAMMA)\n",
        "model = model.to(DEVICE)\n",
        "loss_fn = LossFunction()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTS1XGqki2To"
      },
      "source": [
        "epoch_idx = 0\n",
        "if LOAD_TRAIN_MODEL:\n",
        "    epoch_idx, model = load_checkpoint(model, CHECKPOINT_FILE, DEVICE)\n",
        "\n",
        "model.train()\n",
        "for epoch_idx in range(epoch_idx, NUM_EPOCHS):\n",
        "    metric_fn = MetricFunction(BATCH_SIZE)\n",
        "    train_one_epoch(model, train_dataloader, loss_fn, metric_fn, solver, epoch_idx)\n",
        "    print_single_error(epoch_idx, loss_fn.show(), metric_fn.show())\n",
        "    lr_scheduler.step()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o5nlrHyjhbw",
        "outputId": "0ed15982-6ffd-440a-c44a-e92418079940"
      },
      "source": [
        "if LOAD_TEST_MODEL:\n",
        "    epoch_idx, model = load_checkpoint(model, CHECKPOINT_FILE, DEVICE)\n",
        "\n",
        "model.eval()\n",
        "metric_fn = MetricFunction(BATCH_SIZE)\n",
        "run_test(model, test_dataloader, loss_fn, metric_fn)\n",
        "print_single_error(epoch_idx, loss_fn.show(), metric_fn.show())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:41<00:00,  2.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval_avg_error\n",
            "Epoch: 0, loss=(total:5.6306)\n",
            "======NORMALS=======\n",
            "MSE=1.4260\tRMSE=1.1912\tMAE=0.9610\tMME=1.1729\n",
            "TANGLE11.25=0.2926\tTANGLE22.5=0.3016\tTANGLE30.0=0.3115\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vp_Jvanjqhm"
      },
      "source": [
        "if LOAD_TEST_MODEL:\n",
        "    epoch_idx, model = load_checkpoint(model, CHECKPOINT_FILE, DEVICE)\n",
        "\n",
        "model.eval()\n",
        "images = LoadImages(IMAGES, transform=detect_transform)\n",
        "for images, predictions, path in generatePredictions(model, images):\n",
        "    plot_predictions(images, predictions, [path])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KWNLIzCjwmo"
      },
      "source": [
        "output_dir = os.path.join(OUT_PATH, re.sub(\"[^0-9a-zA-Z]+\", \"-\", dt.now().isoformat()))\n",
        "\n",
        "save_checkpoint(epoch_idx, model, output_dir)"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}